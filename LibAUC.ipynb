{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install libauc\n",
    "#!pip install -r ./Medical-Transformer/requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libauc.losses import AUCMLoss, CrossEntropyLoss\n",
    "from libauc.optimizers import PESG, Adam\n",
    "from libauc.models import DenseNet121, DenseNet169\n",
    "from libauc.datasets import CheXpert\n",
    "\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import random\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn\n",
    "from dataset import ChexpertDataset\n",
    "from model import MultiLabelClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = os.getcwd()\n",
    "DATA_DIR = os.path.join(BASE_DIR, '..', 'data')\n",
    "CheXpert_train_hidden_features_all = np.load(os.path.join(DATA_DIR,'CheXpert_train_hidden_features_all.npy'))\n",
    "CheXpert_train_labels_all = np.load(os.path.join(DATA_DIR,'CheXpert_train_labels_all.npy'))\n",
    "CheXpert_valid_hidden_features_all = np.load(os.path.join(DATA_DIR,'CheXpert_valid_hidden_features_all.npy'))\n",
    "CheXpert_valid_labels_all = np.load(os.path.join(DATA_DIR,'CheXpert_valid_labels_all.npy'))\n",
    "extra_valid_age_sex_df = pd.read_csv(os.path.join(DATA_DIR,'extra_valid_age_sex.csv'))\n",
    "extra_valid_hidden_features = np.load(os.path.join(DATA_DIR,'extra_valid_hidden_features.npy'))\n",
    "extra_valid_labels = np.load(os.path.join(DATA_DIR,'extra_valid_labels.npy'))\n",
    "extra_valid_images = glob(os.path.join(DATA_DIR, 'extraValid', '*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performing some sort of label smoothing\n",
    "#U-Ones\n",
    "# Map all -1's to 1's\n",
    "'''\n",
    "print(CheXpert_train_labels_all.shape)\n",
    "CheXpert_train_labels_all[CheXpert_train_labels_all == -1] = 1\n",
    "CheXpert_valid_labels_all[CheXpert_valid_labels_all == -1] = 1\n",
    "'''\n",
    "\n",
    "#U-Ones-LSR\n",
    "for i in range(CheXpert_train_labels_all.shape[0]):\n",
    "    for j in range(CheXpert_train_labels_all.shape[1]):\n",
    "        if CheXpert_train_labels_all[i,j] == -1:\n",
    "            CheXpert_train_labels_all[i,j] = random.uniform(.55, .85)\n",
    "for i in range(CheXpert_valid_labels_all.shape[0]):\n",
    "    for j in range(CheXpert_valid_labels_all.shape[1]):\n",
    "        if CheXpert_valid_labels_all[i,j] == -1:\n",
    "            CheXpert_valid_labels_all[i,j] = random.uniform(.55, .85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = ChexpertDataset(CheXpert_train_hidden_features_all, y=CheXpert_train_labels_all, scale_X=True)\n",
    "testset = ChexpertDataset(CheXpert_valid_hidden_features_all, y=CheXpert_valid_labels_all, scale_X=True)\n",
    "trainloader = DataLoader(trainset,\n",
    "                         batch_size=32,\n",
    "                         shuffle=True,\n",
    "                         num_workers=2)\n",
    "testloader = DataLoader(testset,\n",
    "                        batch_size=32,\n",
    "                        shuffle=False,\n",
    "                        num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paramaters\n",
    "SEED = 123\n",
    "BATCH_SIZE = 32\n",
    "imratio = 0.3424\n",
    "lr = 0.05 # using smaller learning rate is better\n",
    "gamma = 500\n",
    "weight_decay = 1e-5\n",
    "margin = 1.0\n",
    "\n",
    "# model\n",
    "model = MultiLabelClassification(num_feature=1024, num_class=5)\n",
    "model = model.cuda()\n",
    "\n",
    "# define loss & optimizer\n",
    "Loss = AUCMLoss(imratio=imratio)\n",
    "optimizer = PESG(model, \n",
    "                 a=Loss.a, \n",
    "                 b=Loss.b, \n",
    "                 alpha=Loss.alpha, \n",
    "                 imratio=imratio, \n",
    "                 lr=lr, \n",
    "                 gamma=gamma, \n",
    "                 margin=margin, \n",
    "                 weight_decay=weight_decay)\n",
    "\n",
    "best_val_auc = 0\n",
    "for epoch in range(4):\n",
    "    if epoch > 0:\n",
    "         optimizer.update_regularizer(decay_factor=10)\n",
    "    for idx, data in enumerate(trainloader):\n",
    "        train_data, train_labels = data\n",
    "        train_data, train_labels = train_data.cuda(), train_labels.cuda()\n",
    "        y_pred = model(train_data)\n",
    "        loss = Loss(y_pred, train_labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # validation\n",
    "        if idx % 400 == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():    \n",
    "                test_pred = []\n",
    "                test_true = [] \n",
    "                for jdx, data in enumerate(testloader):\n",
    "                    test_data, test_label = data\n",
    "                    test_data = test_data.cuda()\n",
    "                    y_pred = model(test_data)\n",
    "                    test_pred.append(y_pred.cpu().detach().numpy())\n",
    "                    test_true.append(test_label.numpy())\n",
    "\n",
    "                test_true = np.concatenate(test_true)\n",
    "                test_pred = np.concatenate(test_pred)\n",
    "                #print(test_true[:100], test_pred[:100])\n",
    "                val_auc =  roc_auc_score(test_true, test_pred) \n",
    "                model.train()\n",
    "\n",
    "                if best_val_auc < val_auc:\n",
    "                    best_val_auc = val_auc\n",
    "\n",
    "            print('Epoch=%s, BatchID=%s, Val_AUC=%.4f, lr=%.4f'%(epoch, idx, val_auc,  optimizer.lr))\n",
    "\n",
    "print ('Best Val_AUC is %.4f'%best_val_auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
